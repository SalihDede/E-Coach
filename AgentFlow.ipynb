{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c85447d",
   "metadata": {},
   "source": [
    "< desteklenen model gemini-1.5-flash>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdfbea4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from -r requirements.txt (line 2)) (0.3.27)\n",
      "Requirement already satisfied: langchain-core in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from -r requirements.txt (line 3)) (0.3.72)\n",
      "Requirement already satisfied: langchain-openai in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from -r requirements.txt (line 6)) (0.3.28)\n",
      "Requirement already satisfied: openai in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from -r requirements.txt (line 7)) (1.98.0)\n",
      "Requirement already satisfied: langchain-anthropic in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from -r requirements.txt (line 10)) (0.3.18)\n",
      "Requirement already satisfied: langchain-google-genai in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from -r requirements.txt (line 13)) (2.0.10)\n",
      "Requirement already satisfied: google-generativeai in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from -r requirements.txt (line 14)) (0.8.5)\n",
      "Requirement already satisfied: langchain-huggingface in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from -r requirements.txt (line 17)) (0.3.1)\n",
      "Requirement already satisfied: transformers in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from -r requirements.txt (line 18)) (4.54.1)\n",
      "Requirement already satisfied: huggingface-hub in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from -r requirements.txt (line 19)) (0.34.3)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from -r requirements.txt (line 22)) (1.1.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from -r requirements.txt (line 25)) (2.3.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from -r requirements.txt (line 26)) (1.7.1)\n",
      "Requirement already satisfied: requests in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from -r requirements.txt (line 29)) (2.32.4)\n",
      "Requirement already satisfied: chromadb in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from -r requirements.txt (line 32)) (1.0.15)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from -r requirements.txt (line 41)) (3.10.5)\n",
      "Requirement already satisfied: PyQt5 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from -r requirements.txt (line 44)) (5.15.11)\n",
      "Requirement already satisfied: pyttsx3 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from -r requirements.txt (line 47)) (2.99)\n",
      "Collecting langgraph (from -r requirements.txt (line 48))\n",
      "  Downloading langgraph-0.6.3-py3-none-any.whl.metadata (6.8 kB)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement langgraph-core (from versions: none)\n",
      "ERROR: No matching distribution found for langgraph-core\n"
     ]
    }
   ],
   "source": [
    "# RequirementslarÄ± indir\n",
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0122a9a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-community\n",
      "  Using cached langchain_community-0.3.27-py3-none-any.whl.metadata (2.9 kB)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.66 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from langchain-community) (0.3.72)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.26 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from langchain-community) (0.3.27)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from langchain-community) (2.0.42)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from langchain-community) (2.32.4)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from langchain-community) (6.0.2)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain-community)\n",
      "  Using cached aiohttp-3.12.15-cp311-cp311-win_amd64.whl.metadata (7.9 kB)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from langchain-community) (9.1.2)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
      "  Using cached pydantic_settings-2.10.1-py3-none-any.whl.metadata (3.4 kB)\n",
      "Requirement already satisfied: langsmith>=0.1.125 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from langchain-community) (0.4.11)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
      "  Using cached httpx_sse-0.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: numpy>=1.26.2 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from langchain-community) (2.3.2)\n",
      "Collecting aiohappyeyeballs>=2.5.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.4.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached aiosignal-1.4.0-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached frozenlist-1.7.0-cp311-cp311-win_amd64.whl.metadata (19 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached multidict-6.6.3-cp311-cp311-win_amd64.whl.metadata (5.4 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached propcache-0.3.2-cp311-cp311-win_amd64.whl.metadata (12 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached yarl-1.20.1-cp311-cp311-win_amd64.whl.metadata (76 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Using cached marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from langchain<1.0.0,>=0.3.26->langchain-community) (0.3.9)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from langchain<1.0.0,>=0.3.26->langchain-community) (2.11.7)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (4.14.1)\n",
      "Requirement already satisfied: packaging>=23.2 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.66->langchain-community) (25.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.66->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain-community) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.26->langchain-community) (0.4.1)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.1.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from requests<3,>=2->langchain-community) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from requests<3,>=2->langchain-community) (2025.8.3)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.2.3)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Using cached mypy_extensions-1.1.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from langsmith>=0.1.125->langchain-community) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from langsmith>=0.1.125->langchain-community) (3.11.1)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from langsmith>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from langsmith>=0.1.125->langchain-community) (0.23.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (4.10.0)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (0.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.3.1)\n",
      "Using cached langchain_community-0.3.27-py3-none-any.whl (2.5 MB)\n",
      "Using cached aiohttp-3.12.15-cp311-cp311-win_amd64.whl (453 kB)\n",
      "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Using cached httpx_sse-0.4.1-py3-none-any.whl (8.1 kB)\n",
      "Using cached marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Using cached multidict-6.6.3-cp311-cp311-win_amd64.whl (45 kB)\n",
      "Using cached pydantic_settings-2.10.1-py3-none-any.whl (45 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Using cached yarl-1.20.1-cp311-cp311-win_amd64.whl (86 kB)\n",
      "Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Using cached aiosignal-1.4.0-py3-none-any.whl (7.5 kB)\n",
      "Using cached frozenlist-1.7.0-cp311-cp311-win_amd64.whl (44 kB)\n",
      "Using cached mypy_extensions-1.1.0-py3-none-any.whl (5.0 kB)\n",
      "Using cached propcache-0.3.2-cp311-cp311-win_amd64.whl (41 kB)\n",
      "Installing collected packages: propcache, mypy-extensions, multidict, marshmallow, httpx-sse, frozenlist, aiohappyeyeballs, yarl, typing-inspect, aiosignal, pydantic-settings, dataclasses-json, aiohttp, langchain-community\n",
      "\n",
      "   ----------- ----------------------------  4/14 [httpx-sse]\n",
      "   ---------------------------- ----------- 10/14 [pydantic-settings]\n",
      "   ---------------------------------- ----- 12/14 [aiohttp]\n",
      "   ------------------------------------- -- 13/14 [langchain-community]\n",
      "   ------------------------------------- -- 13/14 [langchain-community]\n",
      "   ------------------------------------- -- 13/14 [langchain-community]\n",
      "   ------------------------------------- -- 13/14 [langchain-community]\n",
      "   ------------------------------------- -- 13/14 [langchain-community]\n",
      "   ------------------------------------- -- 13/14 [langchain-community]\n",
      "   ------------------------------------- -- 13/14 [langchain-community]\n",
      "   ------------------------------------- -- 13/14 [langchain-community]\n",
      "   ------------------------------------- -- 13/14 [langchain-community]\n",
      "   ------------------------------------- -- 13/14 [langchain-community]\n",
      "   ------------------------------------- -- 13/14 [langchain-community]\n",
      "   ------------------------------------- -- 13/14 [langchain-community]\n",
      "   ------------------------------------- -- 13/14 [langchain-community]\n",
      "   ------------------------------------- -- 13/14 [langchain-community]\n",
      "   ------------------------------------- -- 13/14 [langchain-community]\n",
      "   ------------------------------------- -- 13/14 [langchain-community]\n",
      "   ------------------------------------- -- 13/14 [langchain-community]\n",
      "   ------------------------------------- -- 13/14 [langchain-community]\n",
      "   ------------------------------------- -- 13/14 [langchain-community]\n",
      "   ------------------------------------- -- 13/14 [langchain-community]\n",
      "   ------------------------------------- -- 13/14 [langchain-community]\n",
      "   ------------------------------------- -- 13/14 [langchain-community]\n",
      "   ------------------------------------- -- 13/14 [langchain-community]\n",
      "   ------------------------------------- -- 13/14 [langchain-community]\n",
      "   ------------------------------------- -- 13/14 [langchain-community]\n",
      "   ------------------------------------- -- 13/14 [langchain-community]\n",
      "   ------------------------------------- -- 13/14 [langchain-community]\n",
      "   ---------------------------------------- 14/14 [langchain-community]\n",
      "\n",
      "Successfully installed aiohappyeyeballs-2.6.1 aiohttp-3.12.15 aiosignal-1.4.0 dataclasses-json-0.6.7 frozenlist-1.7.0 httpx-sse-0.4.1 langchain-community-0.3.27 marshmallow-3.26.1 multidict-6.6.3 mypy-extensions-1.1.0 propcache-0.3.2 pydantic-settings-2.10.1 typing-inspect-0.9.0 yarl-1.20.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hp\\.conda\\envs\\AI_Agent\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "%pip install -U langchain-community\n",
    "\n",
    "#KÃ¼tÃ¼phane importlarÄ±\n",
    "from dotenv import load_dotenv     # .env dosyasÄ±nÄ± yÃ¼klemek iÃ§in API key\n",
    "from langchain_google_genai import GoogleGenerativeAI, GoogleGenerativeAIEmbeddings # Google LLM kullanmak iÃ§in\n",
    "import requests # HTTP istekleri yapmak iÃ§in\n",
    "import time # Zamanlama iÅŸlemleri iÃ§in - 1 saniyelik bekleme \n",
    "import os # Ã‡evresel deÄŸiÅŸkenleri yÃ¶netmek iÃ§in\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.agents import Tool\n",
    "from langchain.agents import initialize_agent\n",
    "from langchain.agents.agent_types import AgentType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39fee04d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "load_dotenv() # env daki keyi os de cek ve kullan\n",
    "# Ã–rnek kullanÄ±m\n",
    "LLM = GoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    temperature=0.1,\n",
    ")\n",
    "\n",
    "response = LLM.invoke(\"What is the capital of France?\")  # Example usage\n",
    "print(response)  # Output the response from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9167059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dinlenecek endPoint Adresleri\n",
    "ENDPOINT_ATTENTION = \"http://127.0.0.1:8001/attention\"\n",
    "ENDPOINT_SCRIPT = \"http://localhost:5000/get_texts\"\n",
    "ENDPOINT_KYBRD_MOUSE_INTERRUPT = \"http://localhost:5000/api/status\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852e088f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veri Ã§ekme ve iÅŸleme dÃ¶ngÃ¼sÃ¼\n",
    "while True:\n",
    "    try:\n",
    "        response = requests.get(ENDPOINT_ATTENTION)\n",
    "        data = response.json()\n",
    "    except Exception as e:\n",
    "        print(f\"[HATA] ENDPOINT_ATTENTION verisi alÄ±namadÄ±: {e}\")\n",
    "        data = {}\n",
    "\n",
    "    try:\n",
    "        keyboard_response = requests.get(ENDPOINT_KYBRD_MOUSE_INTERRUPT)\n",
    "        keyboard_data = keyboard_response.json()\n",
    "    except Exception as e:\n",
    "        print(f\"[HATA] ENDPOINT_KYBRD_MOUSE_INTERRUPT verisi alÄ±namadÄ±: {e}\")\n",
    "        keyboard_data = {}\n",
    "\n",
    "    try:\n",
    "        script_response = requests.get(ENDPOINT_SCRIPT)\n",
    "        script_data = script_response.json()\n",
    "    except Exception as e:\n",
    "        print(f\"[HATA] ENDPOINT_SCRIPT verisi alÄ±namadÄ±: {e}\")\n",
    "        script_data = {}\n",
    "\n",
    "    time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee0292f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ğŸ§¬ Embedder ve ChromaDB yapÄ±landÄ±rmasÄ± (ilk kullanÄ±mda klasÃ¶r oluÅŸturur)\n",
    "embedding = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "vectordb = Chroma(persist_directory=\"student_memory\", embedding_function=embedding)\n",
    "\n",
    "# ğŸ” RetrievalQA ile geÃ§miÅŸ Ã¶ÄŸrenci verilerini LLM'e baÄŸla\n",
    "qa_chain = RetrievalQA.from_chain_type(\n",
    "    llm=LLM,\n",
    "    retriever=vectordb.as_retriever(search_kwargs={\"k\": 3}),\n",
    "    chain_type=\"stuff\"\n",
    ")\n",
    "\n",
    "\n",
    "# ğŸ§© Son gelen dikkat verilerini ChromaDB'ye kaydet (isteÄŸe baÄŸlÄ± - sadece Ã¶rnek amaÃ§lÄ±)\n",
    "metadata = {\n",
    "    \"attention\": data.get(\"attention\", 0),\n",
    "    \"screen\": data.get(\"head_looking_at_screen\", False),\n",
    "    \"eye_left\": data.get(\"left_eye_open\", False),\n",
    "    \"eye_right\": data.get(\"right_eye_open\", False),\n",
    "    \"att_1min\": data.get(\"attention_1min_avg\", 0),\n",
    "    \"att_5min\": data.get(\"attention_5min_avg\", 0),\n",
    "    \"att_20min\": data.get(\"attention_20min_avg\", 0),\n",
    "    \"att_total\": data.get(\"attention_total_avg\", 0),\n",
    "    \"keyboard_activity\": keyboard_data.get(\"keyboard_activity\", False),\n",
    "    \"mouse_activity\": keyboard_data.get(\"mouse_activity\", False),\n",
    "    \"tab_changed\": keyboard_data.get(\"tab_changed\", False),\n",
    "    \"interaction_status\": keyboard_data.get(\"status\", \"no_status\"),\n",
    "    \"focus_score\": script_data.get(\"focus_score\", 0) #script_data'dan alÄ±nan script benzerlik deÄŸeri\n",
    "}\n",
    "\n",
    "query = f\"\"\"\n",
    "ğŸ“ SEN, yalnÄ±zca dikkat dÃ¼zeyini deÄŸil, Ã¶ÄŸrencinin **Ã¶ÄŸrenme stilini** (VAK modeli: gÃ¶rsel, iÅŸitsel, kinestetik) analiz edebilen ileri dÃ¼zey bir eÄŸitim bilimci ve kiÅŸisel koÃ§sun.\n",
    "\n",
    "AÅŸaÄŸÄ±da, Ã¶ÄŸrencinin dikkat, gÃ¶z takibi, ekran izleme, focus score, klavye/mouse aktivitesi gibi Ã§oklu verileri yer alÄ±yor. GÃ¶revin:\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ¯ 1. Dikkat Verisi DeÄŸerlendirmesi\n",
    "\n",
    "* AnlÄ±k dikkat dÃ¼zeyi (attention), geÃ§miÅŸ ortalamalar (1dk, 5dk, 20dk)\n",
    "* Ekrana bakma durumu ve gÃ¶z aÃ§Ä±klÄ±klarÄ±\n",
    "* Focus score (senaryo iÃ§eriÄŸine odaklÄ±lÄ±k)\n",
    "\n",
    "BunlarÄ± deÄŸerlendirerek Ã¶ÄŸrencinin **anlÄ±k dikkat seviyesini** yorumla ve gerekirse Ã§Ã¶zÃ¼m Ã¼retici Ã¶neriler sun.\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ§  2. Ã–ÄŸrenme TarzÄ± (VAK) Tahmini\n",
    "\n",
    "Verilere dayanarak Ã¶ÄŸrencinin baskÄ±n Ã¶ÄŸrenme tarzÄ±nÄ± (gÃ¶rsel, iÅŸitsel, kinestetik) **tahmin et**. EÄŸer karÄ±ÅŸÄ±k bir profil varsa bu kombinasyonu aÃ§Ä±kla.\n",
    "\n",
    "- GÃ¶z takibi, ekrana odak, yÃ¼ksek attention â†’ gÃ¶rsel\n",
    "- Focus score yÃ¼ksek, sesli konuÅŸma sÄ±rasÄ±nda dikkatli â†’ iÅŸitsel\n",
    "- Klavye/mouse etkileÅŸimi, sekme deÄŸiÅŸimi â†’ kinestetik\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ› ï¸ 3. Ã–ÄŸrenciye Ã–zel Uygulama Ã–nerileri\n",
    "\n",
    "Her tarza uygun aÅŸaÄŸÄ±daki Ã¶rneklerden yararlanarak Ã¶neriler ver:\n",
    "\n",
    "| Ã–ÄŸrenme TarzÄ± | Ã–neriler |\n",
    "|---------------|----------|\n",
    "| GÃ¶rsel | Diyagram, video, grafik, kavram haritasÄ± |\n",
    "| Ä°ÅŸitsel | Podcast, sesli anlatÄ±m, tekrar ses kayÄ±tlarÄ± |\n",
    "| Kinestetik | UygulamalÄ± etkinlikler, mini projeler, yazâ€‘Ã§izâ€‘hareket |\n",
    "\n",
    "---\n",
    "\n",
    "## âœ¨ 4. Geri Bildirim Metni\n",
    "\n",
    "Destekleyici, motive edici, koÃ§vari bir geri bildirim oluÅŸtur.\n",
    "\n",
    "- Dikkat yÃ¼ksekse: Takdir et, gÃ¼Ã§lÃ¼ yÃ¶nleri vurgula\n",
    "- Dikkat dÃ¼ÅŸÃ¼kse: Cesaretlendir, Ã§Ã¶zÃ¼m Ã¶ner\n",
    "- Her zaman pozitif yaklaÅŸÄ±m kullan\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ”¢ Dikkat & EtkileÅŸim Verileri\n",
    "\n",
    "- Dikkat skoru: {data.get('attention',)}\n",
    "- 1dk ort.: {data.get('attention_1min_avg')}\n",
    "- 5dk ort.: {data.get('attention_5min_avg')}\n",
    "- 20dk ort.: {data.get('attention_20min_avg')}\n",
    "- Genel ort.: {data.get('attention_total_avg')}\n",
    "- Ekrana bakÄ±yor mu: {data.get('head_looking_at_screen')}\n",
    "- GÃ¶z durumu: Sol={data.get('left_eye_open', False)}, SaÄŸ={data.get('right_eye_open')}\n",
    "- Focus Score (senaryo iÃ§eriÄŸine odak): {script_data.get('focus_score')}\n",
    "- Klavye: {keyboard_data.get('keyboard_activity')}\n",
    "- Mouse: {keyboard_data.get('mouse_activity')}\n",
    "- Sekme deÄŸiÅŸti mi: {keyboard_data.get('tab_changed')}\n",
    "- EtkileÅŸim durumu kodu: {keyboard_data.get('status')}\n",
    "\n",
    "---\n",
    "\n",
    "LÃ¼tfen Ã¶nce veri analizi yap, ardÄ±ndan Ã¶ÄŸrenme tarzÄ±nÄ± tahmin et, sonra Ã¶nerilerde bulun ve en son bir paragraflÄ±k destekleyici koÃ§luk geri bildirimi oluÅŸtur.\n",
    "\"\"\"\n",
    "\n",
    "vectordb.add_texts([query], metadatas=[metadata])\n",
    "\n",
    "\n",
    "coach_feedback = qa_chain.run(query)\n",
    "\n",
    "print(\"\\nğŸ“ KoÃ§ TavrÄ± ile KiÅŸisel Geri Bildirim:\")\n",
    "print(coach_feedback)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c37c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ã–ÄŸrenci FonksiyonlarÄ±\n",
    "# 1 - Dikkatin DaÄŸÄ±ldÄ± UyarÄ±sÄ± (GÃ¶rsel & Sesli)\n",
    "# âœ… DÄ°KKAT DAÄILDI UYARI MODÃœLÃœ\n",
    "def dikkat_uyarisi_ver(data: dict):\n",
    "    try:\n",
    "        dikkat_dagit = False\n",
    "\n",
    "        # ğŸ‘€ Ekrana bakmÄ±yorsa veya dikkat seviyesi Ã§ok dÃ¼ÅŸÃ¼kse\n",
    "        if not data[\"head_looking_at_screen\"] or data[\"attention\"] < 0.5:\n",
    "            dikkat_dagit = True\n",
    "\n",
    "        if dikkat_dagit:\n",
    "            print(\"âš ï¸ Dikkatin daÄŸÄ±ldÄ±! LÃ¼tfen odaklan.\")\n",
    "            \n",
    "            # ğŸ”Š Sesli uyarÄ± (Windows iÃ§in)\n",
    "            try:\n",
    "                import winsound\n",
    "                winsound.Beep(1000, 400)\n",
    "            except:\n",
    "                pass  # MacOS/Linux iÃ§in farklÄ± Ã§Ã¶zÃ¼mler eklenebilir\n",
    "\n",
    "            # ğŸ¨ Terminal gÃ¶rsel simÃ¼lasyonu (UI'ye entegre edilebilir)\n",
    "            print(\"\\033[91m[Ã‡erÃ§eve RENGÄ°: KIRMIZI - ODAK YOK]\\033[0m\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ğŸš¨ Dikkat modÃ¼lÃ¼ hatasÄ±: {e}\")\n",
    "        \n",
    "        \n",
    "# 2 - Yorgunluk AlgÄ±lama ve Mola Ã–nerisi\n",
    "# âœ… CROMADB TABANLI YORGUNLUK ALGILAMA MODÃœLÃœ\n",
    "def mola_onerisi_chromadb(vectordb):\n",
    "    try:\n",
    "        # Chroma'dan son 10 kaydÄ± al\n",
    "        recent_docs = vectordb.similarity_search(\"attention\", k=10)\n",
    "\n",
    "        # GeÃ§erli kayÄ±tlar varsa, dikkat_20min skorlarÄ±nÄ± topla\n",
    "        attention_20mins = []\n",
    "        for doc in recent_docs:\n",
    "            att = doc.metadata.get(\"att_20min\")\n",
    "            if isinstance(att, (int, float)):\n",
    "                attention_20mins.append(att)\n",
    "        \n",
    "        # Ortalama hesapla\n",
    "        if len(attention_20mins) >= 3:  # En az 3 veri noktasÄ± ÅŸartÄ±\n",
    "            avg_att_20min = sum(attention_20mins) / len(attention_20mins)\n",
    "\n",
    "            if avg_att_20min < 0.6:\n",
    "                print(\"ğŸ˜´ Son 20 dakikada dikkat seviyen ortalama %60'Ä±n altÄ±nda.\")\n",
    "                print(\"ğŸ’¡ Bu odak kaybÄ±, zihinsel yorgunluÄŸa iÅŸaret ediyor olabilir.\")\n",
    "                print(\"â¸ï¸ KÄ±sa bir mola vermeyi dene! Bir yÃ¼rÃ¼yÃ¼ÅŸ veya esneme iyi gelebilir.\")\n",
    "\n",
    "                try:\n",
    "                    import winsound\n",
    "                    winsound.Beep(800, 500)\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "                print(\"\\033[95m[Mola Tavsiyesi: Chroma geÃ§miÅŸ analizine dayalÄ± dÃ¼ÅŸÃ¼k dikkat algÄ±landÄ±.]\\033[0m\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ğŸš¨ Chroma yorgunluk modÃ¼lÃ¼ hatasÄ±: {e}\")\n",
    "\n",
    "\n",
    "\n",
    "# 3 - LLM Destekli Ã–ÄŸrenme Periyodu Ã–nerisi\n",
    "# âœ… LLM DESTEKLÄ°, TEKNÄ°K SINIRLAMASI OLMAYAN Ã–ÄRENME PERÄ°YODU Ã–NERÄ°SÄ°\n",
    "def periyot_onerisi_llm_ileri(vectordb, qa_chain):\n",
    "    try:\n",
    "        recent_docs = vectordb.similarity_search(\"attention\", k=15)\n",
    "        attention_values = []\n",
    "        focus_scores = []\n",
    "        metadata_list = []\n",
    "\n",
    "        for doc in recent_docs:\n",
    "            att = doc.metadata.get(\"attention\")\n",
    "            focus = doc.metadata.get(\"focus_score\", 0)\n",
    "\n",
    "            if isinstance(att, (float, int)):\n",
    "                attention_values.append(att)\n",
    "            if isinstance(focus, (float, int)):\n",
    "                focus_scores.append(focus)\n",
    "\n",
    "            metadata_list.append(doc.metadata)\n",
    "\n",
    "        if len(attention_values) < 5:\n",
    "            print(\"ğŸ“Š Ã–ÄŸrenciye Ã¶zel Ã¶neri iÃ§in yeterli veri yok.\")\n",
    "            return\n",
    "\n",
    "        avg_attention = sum(attention_values) / len(attention_values)\n",
    "        avg_focus_score = sum(focus_scores) / len(focus_scores) if focus_scores else 0\n",
    "\n",
    "        attention_summary = \"\\n\".join([\n",
    "            f\"- Dikkat: {round(m.get('attention', 0), 2)}, 20dk Ort: {round(m.get('att_20min', 0), 2)}, ğŸ™ï¸ Focus Score: {round(m.get('focus_score', 0), 2)}, Klavye: {m.get('keyboard_activity')}, Mouse: {m.get('mouse_activity')}, Sekme: {m.get('tab_changed')}\"\n",
    "            for m in metadata_list\n",
    "        ])\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "ğŸ“š SEN, deneyimli bir eÄŸitim bilimci ve koÃ§sun. AÅŸaÄŸÄ±daki dikkat geÃ§miÅŸine sahip bir Ã¶ÄŸrenciyi analiz ederek ona en uygun **Ã§alÄ±ÅŸma periyodu ve Ã¶ÄŸrenme tekniÄŸini** Ã¶nereceksin.\n",
    "\n",
    "ğŸ” Sadece klasik tekniklerle sÄ±nÄ±rlÄ± kalma! Gerekirse aÅŸaÄŸÄ±daki gibi alternatif tekniklerden birini ya da birkaÃ§Ä±nÄ± birleÅŸtir:\n",
    "- 52/17 TekniÄŸi\n",
    "- Ultradian Ritim\n",
    "- Time Blocking\n",
    "- Active Recall\n",
    "- Feynman TekniÄŸi\n",
    "- Zihin HaritasÄ± ile BÃ¶lÃ¼mlendirme\n",
    "- Pomodoro\n",
    "- Deep Work\n",
    "- Interleaving / Spaced Repetition\n",
    "- GÃ¶rsel-AkÄ±ÅŸ HaritasÄ± TekniÄŸi\n",
    "- Motion-Based Learning (kinestetikler iÃ§in)\n",
    "- Mikro GÃ¶rev ParÃ§alama vs.\n",
    "\n",
    "ğŸ¯ GÃ¶revlerin:\n",
    "1. Ã–ÄŸrencinin dikkat alÄ±ÅŸkanlÄ±klarÄ±nÄ± ve davranÄ±ÅŸ Ã¶rÃ¼ntÃ¼lerini analiz et.\n",
    "2. En uygun 1 veya 2 teknik Ã¶ner. Sebepleriyle aÃ§Ä±kla.\n",
    "3. NasÄ±l uygulanacaÄŸÄ±nÄ± aÅŸamalÄ± olarak anlat.\n",
    "4. GÃ¼nlÃ¼k takip planÄ± Ã¶ner.\n",
    "\n",
    "ğŸ§  Veriler:\n",
    "{attention_summary}\n",
    "\n",
    "ğŸ“Š Ortalama dikkat skoru: {round(avg_attention, 2)}\n",
    "ğŸ™ï¸ OdaklÄ± KonuÅŸma Skoru (focus_score): {round(avg_focus_score, 2)}\n",
    "\n",
    "ğŸ’¡ Ek Not: Focus Score, Ã¶ÄŸrencinin Ã¶ÄŸrenme sÄ±rasÄ±nda konuÅŸma senaryosu iÃ§eriÄŸine olan odaklanma dÃ¼zeyidir. YÃ¼ksekse, sesli anlatÄ±m ve sÃ¶zel iÃ§eriklerin etkili olabileceÄŸi bir Ã¶ÄŸrenme stiline iÅŸaret edebilir.\n",
    "\"\"\"\n",
    "\n",
    "        feedback = qa_chain.run(prompt)\n",
    "\n",
    "        print(\"\\nğŸ§  LLM Destekli KiÅŸisel Ã–ÄŸrenme Stratejisi Ã–nerisi:\")\n",
    "        print(feedback)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"ğŸš¨ GeliÅŸmiÅŸ LLM Ã¶neri modÃ¼lÃ¼ hatasÄ±: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a18c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLMâ€™in kullanabileceÄŸi araÃ§larÄ± tanÄ±mlÄ±yoruz\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"DikkatUyarisi\",\n",
    "        func=dikkat_uyarisi_ver,\n",
    "        description=\"Ã–ÄŸrencinin dikkat seviyesi dÃ¼ÅŸÃ¼kse uyarÄ± verir. (attention < 0.5)\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"MolaOnerisi\",\n",
    "        func=lambda x: mola_onerisi_chromadb(vectordb),\n",
    "        description=\"Son 20 dakikadaki dikkat ortalamasÄ± dÃ¼ÅŸÃ¼kse mola Ã¶nerir. (att_20min < 0.6)\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"OgrenmePeriyoduOnerisi\",\n",
    "        func=lambda x: periyot_onerisi_llm_ileri(vectordb, qa_chain),\n",
    "        description=\"Ã–ÄŸrenci dikkat geÃ§miÅŸine gÃ¶re en uygun Ã¶ÄŸrenme stratejisini Ã¶nerir.\"\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787c2839",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent oluÅŸturma\n",
    "# LLM + Toolâ€™larÄ± bir araya getirerek agent oluÅŸturuyoruz\n",
    "agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=LLM,\n",
    "    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abaaed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent Prompt - GÃ¶revi\n",
    "\n",
    "agent_prompt = \"\"\"\n",
    "AÅŸaÄŸÄ±da Ã¶ÄŸrencinin dikkat verileri yer almakta.\n",
    "Sen deneyimli bir eÄŸitim koÃ§usun. Bu verileri analiz et, duruma gÃ¶re aÅŸaÄŸÄ±daki gÃ¶revleri sÄ±rayla uygula:\n",
    "\n",
    "1. Dikkat dÃ¼ÅŸÃ¼kse uyarÄ± ver.\n",
    "2. Son 20dk dikkat ortalamasÄ± dÃ¼ÅŸÃ¼kse mola Ã¶ner.\n",
    "3. Ã–ÄŸrencinin dikkat geÃ§miÅŸine gÃ¶re Ã§alÄ±ÅŸma periyodu ve tekniÄŸi Ã¶ner.\n",
    "\n",
    "Gerekli gÃ¶revleri sÄ±rasÄ±yla kendi kararÄ±nla seÃ§ ve uygula.\n",
    "\"\"\"\n",
    "\n",
    "agent.run(agent_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "785d7db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 - Dikkatin DaÄŸÄ±ldÄ± UyarÄ±sÄ± (GÃ¶rsel & Sesli) TEST\n",
    "dummy_data = {\n",
    "    \"attention\": 0.42,\n",
    "    \"head_looking_at_screen\": False,\n",
    "    \"left_eye_open\": True,\n",
    "    \"right_eye_open\": True,\n",
    "    \"attention_1min_avg\": 0.51,\n",
    "    \"attention_5min_avg\": 0.54,\n",
    "    \"attention_20min_avg\": 0.50,\n",
    "    \"attention_total_avg\": 0.52\n",
    "}\n",
    "\n",
    "# dikkat_uyarisi_ver(dummy_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367a2d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 - Yorgunluk AlgÄ±lama ve Mola Ã–nerisi TEST\n",
    "\n",
    "# ğŸ§ª TEST (Senaryo: son 20dk ortalamasÄ± Ã§ok dÃ¼ÅŸÃ¼k)\n",
    "# ğŸ§ª Vectordb Ã¼stÃ¼nden test etmek iÃ§in Ã§aÄŸÄ±r\n",
    "# mola_onerisi_chromadb(vectordb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58795b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 - LLM Destekli Ã–ÄŸrenme Periyodu Ã–nerisi TEST\n",
    "\n",
    "#periyot_onerisi_llm_ileri(vectordb, qa_chain)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_Agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
