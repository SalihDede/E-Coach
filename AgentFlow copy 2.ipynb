{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6e90061",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "30f2a660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from -r requirements.txt (line 2)) (0.3.27)\n",
      "Requirement already satisfied: langchain-core in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from -r requirements.txt (line 3)) (0.3.72)\n",
      "Requirement already satisfied: langchain-openai in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from -r requirements.txt (line 6)) (0.3.28)\n",
      "Requirement already satisfied: openai in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from -r requirements.txt (line 7)) (1.98.0)\n",
      "Requirement already satisfied: langchain-anthropic in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from -r requirements.txt (line 10)) (0.3.18)\n",
      "Requirement already satisfied: langchain-google-genai in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from -r requirements.txt (line 13)) (2.0.10)\n",
      "Requirement already satisfied: google-generativeai in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from -r requirements.txt (line 14)) (0.8.5)\n",
      "Requirement already satisfied: langchain-huggingface in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from -r requirements.txt (line 17)) (0.3.1)\n",
      "Requirement already satisfied: transformers in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from -r requirements.txt (line 18)) (4.54.1)\n",
      "Requirement already satisfied: huggingface-hub in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from -r requirements.txt (line 19)) (0.34.3)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from -r requirements.txt (line 22)) (1.1.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from -r requirements.txt (line 25)) (2.3.2)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from -r requirements.txt (line 26)) (1.7.1)\n",
      "Requirement already satisfied: requests in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from -r requirements.txt (line 29)) (2.32.4)\n",
      "Requirement already satisfied: chromadb in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from -r requirements.txt (line 32)) (1.0.15)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from -r requirements.txt (line 41)) (3.10.5)\n",
      "Requirement already satisfied: PyQt5 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from -r requirements.txt (line 44)) (5.15.11)\n",
      "Requirement already satisfied: pyttsx3 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from -r requirements.txt (line 47)) (2.99)\n",
      "Requirement already satisfied: langgraph in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from -r requirements.txt (line 48)) (0.6.3)\n",
      "Requirement already satisfied: flask-cors in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from -r requirements.txt (line 49)) (6.0.1)\n",
      "Requirement already satisfied: reportlab in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from -r requirements.txt (line 50)) (4.4.3)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from langchain->-r requirements.txt (line 2)) (0.3.9)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from langchain->-r requirements.txt (line 2)) (0.4.11)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from langchain->-r requirements.txt (line 2)) (2.11.7)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from langchain->-r requirements.txt (line 2)) (2.0.42)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from langchain->-r requirements.txt (line 2)) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from langchain-core->-r requirements.txt (line 3)) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from langchain-core->-r requirements.txt (line 3)) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from langchain-core->-r requirements.txt (line 3)) (4.14.1)\n",
      "Requirement already satisfied: packaging>=23.2 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from langchain-core->-r requirements.txt (line 3)) (25.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from requests->-r requirements.txt (line 29)) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from requests->-r requirements.txt (line 29)) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from requests->-r requirements.txt (line 29)) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from requests->-r requirements.txt (line 29)) (2025.8.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core->-r requirements.txt (line 3)) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain->-r requirements.txt (line 2)) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain->-r requirements.txt (line 2)) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain->-r requirements.txt (line 2)) (0.4.1)\n",
      "Requirement already satisfied: greenlet>=1 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain->-r requirements.txt (line 2)) (3.2.3)\n",
      "Requirement already satisfied: tiktoken<1,>=0.7 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from langchain-openai->-r requirements.txt (line 6)) (0.9.0)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from openai->-r requirements.txt (line 7)) (4.10.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from openai->-r requirements.txt (line 7)) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from openai->-r requirements.txt (line 7)) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from openai->-r requirements.txt (line 7)) (0.10.0)\n",
      "Requirement already satisfied: sniffio in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from openai->-r requirements.txt (line 7)) (1.3.1)\n",
      "Requirement already satisfied: tqdm>4 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from openai->-r requirements.txt (line 7)) (4.67.1)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 7)) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai->-r requirements.txt (line 7)) (0.16.0)\n",
      "Requirement already satisfied: regex>=2022.1.18 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from tiktoken<1,>=0.7->langchain-openai->-r requirements.txt (line 6)) (2025.7.34)\n",
      "Requirement already satisfied: anthropic<1,>=0.60.0 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from langchain-anthropic->-r requirements.txt (line 10)) (0.60.0)\n",
      "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from langchain-google-genai->-r requirements.txt (line 13)) (1.2.0)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from google-generativeai->-r requirements.txt (line 14)) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from google-generativeai->-r requirements.txt (line 14)) (2.25.1)\n",
      "Requirement already satisfied: google-api-python-client in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from google-generativeai->-r requirements.txt (line 14)) (2.177.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from google-generativeai->-r requirements.txt (line 14)) (2.40.3)\n",
      "Requirement already satisfied: protobuf in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from google-generativeai->-r requirements.txt (line 14)) (5.29.5)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai->-r requirements.txt (line 14)) (1.26.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from google-api-core->google-generativeai->-r requirements.txt (line 14)) (1.70.0)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai->-r requirements.txt (line 14)) (1.74.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai->-r requirements.txt (line 14)) (1.71.2)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai->-r requirements.txt (line 14)) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai->-r requirements.txt (line 14)) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai->-r requirements.txt (line 14)) (4.9.1)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth>=2.15.0->google-generativeai->-r requirements.txt (line 14)) (0.6.1)\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from langchain-huggingface->-r requirements.txt (line 17)) (0.21.4)\n",
      "Requirement already satisfied: filelock in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from transformers->-r requirements.txt (line 18)) (3.18.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from transformers->-r requirements.txt (line 18)) (0.5.3)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from huggingface-hub->-r requirements.txt (line 19)) (2025.7.0)\n",
      "Requirement already satisfied: scipy>=1.8.0 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 26)) (1.16.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 26)) (1.5.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from scikit-learn->-r requirements.txt (line 26)) (3.6.0)\n",
      "Requirement already satisfied: build>=1.0.3 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from chromadb->-r requirements.txt (line 32)) (1.3.0)\n",
      "Requirement already satisfied: pybase64>=1.4.1 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from chromadb->-r requirements.txt (line 32)) (1.4.2)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 32)) (0.35.0)\n",
      "Requirement already satisfied: posthog<6.0.0,>=2.4.0 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from chromadb->-r requirements.txt (line 32)) (5.4.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from chromadb->-r requirements.txt (line 32)) (1.22.1)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from chromadb->-r requirements.txt (line 32)) (1.36.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from chromadb->-r requirements.txt (line 32)) (1.36.0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from chromadb->-r requirements.txt (line 32)) (1.36.0)\n",
      "Requirement already satisfied: pypika>=0.48.9 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from chromadb->-r requirements.txt (line 32)) (0.48.9)\n",
      "Requirement already satisfied: overrides>=7.3.1 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from chromadb->-r requirements.txt (line 32)) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from chromadb->-r requirements.txt (line 32)) (6.5.2)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from chromadb->-r requirements.txt (line 32)) (4.3.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from chromadb->-r requirements.txt (line 32)) (0.16.0)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from chromadb->-r requirements.txt (line 32)) (33.1.0)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from chromadb->-r requirements.txt (line 32)) (5.2.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from chromadb->-r requirements.txt (line 32)) (3.11.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from chromadb->-r requirements.txt (line 32)) (14.1.0)\n",
      "Requirement already satisfied: jsonschema>=4.19.0 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from chromadb->-r requirements.txt (line 32)) (4.25.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb->-r requirements.txt (line 32)) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.2 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb->-r requirements.txt (line 32)) (2.9.0.post0)\n",
      "Requirement already satisfied: backoff>=1.10.0 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from posthog<6.0.0,>=2.4.0->chromadb->-r requirements.txt (line 32)) (2.2.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from matplotlib->-r requirements.txt (line 41)) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from matplotlib->-r requirements.txt (line 41)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from matplotlib->-r requirements.txt (line 41)) (4.59.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from matplotlib->-r requirements.txt (line 41)) (1.4.8)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from matplotlib->-r requirements.txt (line 41)) (11.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from matplotlib->-r requirements.txt (line 41)) (3.2.3)\n",
      "Requirement already satisfied: PyQt5-sip<13,>=12.15 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from PyQt5->-r requirements.txt (line 44)) (12.17.0)\n",
      "Requirement already satisfied: PyQt5-Qt5<5.16.0,>=5.15.2 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from PyQt5->-r requirements.txt (line 44)) (5.15.2)\n",
      "Requirement already satisfied: comtypes in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from pyttsx3->-r requirements.txt (line 47)) (1.4.11)\n",
      "Requirement already satisfied: pypiwin32 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from pyttsx3->-r requirements.txt (line 47)) (223)\n",
      "Requirement already satisfied: pywin32 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from pyttsx3->-r requirements.txt (line 47)) (311)\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.1.0 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from langgraph->-r requirements.txt (line 48)) (2.1.1)\n",
      "Requirement already satisfied: langgraph-prebuilt<0.7.0,>=0.6.0 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from langgraph->-r requirements.txt (line 48)) (0.6.3)\n",
      "Requirement already satisfied: langgraph-sdk<0.3.0,>=0.2.0 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from langgraph->-r requirements.txt (line 48)) (0.2.0)\n",
      "Requirement already satisfied: xxhash>=3.5.0 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from langgraph->-r requirements.txt (line 48)) (3.5.0)\n",
      "Requirement already satisfied: ormsgpack>=1.10.0 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from langgraph-checkpoint<3.0.0,>=2.1.0->langgraph->-r requirements.txt (line 48)) (1.10.0)\n",
      "Requirement already satisfied: flask>=0.9 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from flask-cors->-r requirements.txt (line 49)) (3.1.1)\n",
      "Requirement already satisfied: Werkzeug>=0.7 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from flask-cors->-r requirements.txt (line 49)) (3.1.3)\n",
      "Requirement already satisfied: pyproject_hooks in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from build>=1.0.3->chromadb->-r requirements.txt (line 32)) (1.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from build>=1.0.3->chromadb->-r requirements.txt (line 32)) (0.4.6)\n",
      "Requirement already satisfied: blinker>=1.9.0 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from flask>=0.9->flask-cors->-r requirements.txt (line 49)) (1.9.0)\n",
      "Requirement already satisfied: click>=8.1.3 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from flask>=0.9->flask-cors->-r requirements.txt (line 49)) (8.2.1)\n",
      "Requirement already satisfied: itsdangerous>=2.2.0 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from flask>=0.9->flask-cors->-r requirements.txt (line 49)) (2.2.0)\n",
      "Requirement already satisfied: jinja2>=3.1.2 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from flask>=0.9->flask-cors->-r requirements.txt (line 49)) (3.1.6)\n",
      "Requirement already satisfied: markupsafe>=2.1.1 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from flask>=0.9->flask-cors->-r requirements.txt (line 49)) (3.0.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from jsonschema>=4.19.0->chromadb->-r requirements.txt (line 32)) (25.3.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from jsonschema>=4.19.0->chromadb->-r requirements.txt (line 32)) (2025.4.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from jsonschema>=4.19.0->chromadb->-r requirements.txt (line 32)) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from jsonschema>=4.19.0->chromadb->-r requirements.txt (line 32)) (0.26.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 32)) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 32)) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 32)) (3.3.1)\n",
      "Requirement already satisfied: durationpy>=0.7 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 32)) (0.10)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from langsmith>=0.1.17->langchain->-r requirements.txt (line 2)) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from langsmith>=0.1.17->langchain->-r requirements.txt (line 2)) (0.23.0)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 32)) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 32)) (25.2.10)\n",
      "Requirement already satisfied: sympy in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 32)) (1.14.0)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb->-r requirements.txt (line 32)) (8.7.0)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.2.0->chromadb->-r requirements.txt (line 32)) (3.23.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.36.0 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 32)) (1.36.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.36.0 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 32)) (1.36.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.57b0 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from opentelemetry-sdk>=1.2.0->chromadb->-r requirements.txt (line 32)) (0.57b0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from rich>=10.11.0->chromadb->-r requirements.txt (line 32)) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from rich>=10.11.0->chromadb->-r requirements.txt (line 32)) (2.19.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb->-r requirements.txt (line 32)) (0.1.2)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from typer>=0.9.0->chromadb->-r requirements.txt (line 32)) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 32)) (0.6.4)\n",
      "Requirement already satisfied: watchfiles>=0.13 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 32)) (1.1.0)\n",
      "Requirement already satisfied: websockets>=10.4 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 32)) (15.0.1)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 32)) (10.0)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 32)) (3.5.4)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from google-api-python-client->google-generativeai->-r requirements.txt (line 14)) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from google-api-python-client->google-generativeai->-r requirements.txt (line 14)) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from google-api-python-client->google-generativeai->-r requirements.txt (line 14)) (4.2.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\hp\\.conda\\envs\\ai_agent\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb->-r requirements.txt (line 32)) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -r requirements.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5140dd63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Hp\\.conda\\envs\\AI_Agent\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "GeliÅŸmiÅŸ Ã¶ÄŸrenme koÃ§u.\n",
    "Bu betik, Ã¶ÄŸrencinin dikkat ve etkileÅŸim verilerini gerÃ§ek zamanlÄ± olarak toplayarak\n",
    "ChromaDB'de etiketli bir ÅŸekilde saklar ve heuristik kurallara gÃ¶re geri bildirim Ã¼retir.\n",
    "\"\"\"\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import requests\n",
    "import time\n",
    "import pyttsx3\n",
    "import random\n",
    "import threading\n",
    "\n",
    "from reportlab.pdfgen import canvas\n",
    "from reportlab.lib.pagesizes import A4\n",
    "from langchain_google_genai import GoogleGenerativeAI, GoogleGenerativeAIEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.agents import Tool, initialize_agent\n",
    "from langchain.agents.agent_types import AgentType\n",
    "from flask import Flask, request, jsonify, send_file\n",
    "from flask_cors import CORS\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2bad60",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60de51d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Google API anahtarÄ± yÃ¼klendi\n",
      "âœ… Google AI modelleri baÅŸarÄ±yla yÃ¼klendi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_29520\\963484775.py:27: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  vectordb = Chroma(persist_directory=\"student_memory\", embedding_function=embedding)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ChromaDB baÅŸarÄ±yla baÅŸlatÄ±ldÄ±\n",
      "âœ… QA Chain baÅŸarÄ±yla oluÅŸturuldu\n"
     ]
    }
   ],
   "source": [
    "load_dotenv()\n",
    "STUDENT_ID = \"ogrenci_001\"\n",
    "\n",
    "# Google API key kontrolÃ¼\n",
    "api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "if not api_key:\n",
    "    print(\"âŒ GOOGLE_API_KEY bulunamadÄ±! .env dosyasÄ±nÄ± kontrol edin.\")\n",
    "    raise ValueError(\"Google API anahtarÄ± gerekli\")\n",
    "\n",
    "print(\"âœ… Google API anahtarÄ± yÃ¼klendi\")\n",
    "\n",
    "try:\n",
    "    LLM = GoogleGenerativeAI(model=\"gemini-2.0-flash-exp\", temperature=0.1)\n",
    "    embedding = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")\n",
    "    print(\"âœ… Google AI modelleri baÅŸarÄ±yla yÃ¼klendi\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Google AI model yÃ¼kleme hatasÄ±: {e}\")\n",
    "    print(\"ğŸ”„ Alternatif model deneniyor...\")\n",
    "    try:\n",
    "        LLM = GoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0.1)\n",
    "        print(\"âœ… Alternatif model yÃ¼klendi\")\n",
    "    except Exception as e2:\n",
    "        print(f\"âŒ Alternatif model de baÅŸarÄ±sÄ±z: {e2}\")\n",
    "        raise\n",
    "\n",
    "try:\n",
    "    vectordb = Chroma(persist_directory=\"student_memory\", embedding_function=embedding)\n",
    "    print(\"âœ… ChromaDB baÅŸarÄ±yla baÅŸlatÄ±ldÄ±\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ChromaDB baÅŸlatma hatasÄ±: {e}\")\n",
    "    # Yeni bir ChromaDB oluÅŸturmayÄ± dene\n",
    "    import shutil\n",
    "    try:\n",
    "        shutil.rmtree(\"student_memory\", ignore_errors=True)\n",
    "        vectordb = Chroma(persist_directory=\"student_memory\", embedding_function=embedding)\n",
    "        print(\"âœ… ChromaDB yeniden oluÅŸturuldu\")\n",
    "    except Exception as e2:\n",
    "        print(f\"âŒ ChromaDB yeniden oluÅŸturma hatasÄ±: {e2}\")\n",
    "        raise\n",
    "\n",
    "try:\n",
    "    qa_chain = RetrievalQA.from_chain_type(\n",
    "        llm=LLM,\n",
    "        retriever=vectordb.as_retriever(search_kwargs={\"k\": 3}),\n",
    "        chain_type=\"stuff\"\n",
    "    )\n",
    "    print(\"âœ… QA Chain baÅŸarÄ±yla oluÅŸturuldu\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ QA Chain oluÅŸturma hatasÄ±: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2d5938",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40f9df66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Veri akÄ±ÅŸÄ±nÄ± saÄŸlayan endpointler\n",
    "ENDPOINT_ATTENTION = \"http://127.0.0.1:8001/attention\"\n",
    "ENDPOINT_SCRIPT = \"http://localhost:5002/get_texts\"\n",
    "ENDPOINT_KYBRD_MOUSE_INTERRUPT = \"http://localhost:5001/api/status\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bbaa5c",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a9fe8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def dikkat_uyarisi_ver(_):\n",
    "    try:\n",
    "        recent = vectordb.similarity_search(\"attention\", k=1)[0]\n",
    "        data = recent.metadata\n",
    "        if not data.get(\"screen\", False) or data.get(\"attention\", 0) < 0.5:\n",
    "            print(\"âš ï¸ Dikkatin daÄŸÄ±ldÄ±! LÃ¼tfen odaklan.\")\n",
    "            try:\n",
    "                import winsound\n",
    "                winsound.Beep(1000, 400)\n",
    "            except:\n",
    "                pass\n",
    "            print(\"\\033[91m[Ã‡erÃ§eve RENGÄ°: KIRMIZI - ODAK YOK]\\033[0m\")\n",
    "    except Exception as e:\n",
    "        print(f\"ğŸš¨ Dikkat modÃ¼lÃ¼ hatasÄ±: {e}\")\n",
    "\n",
    "def mola_onerisi_chromadb(_):\n",
    "    try:\n",
    "        recent_docs = vectordb.similarity_search(\"attention\", k=10)\n",
    "        att_20s = [\n",
    "            doc.metadata.get(\"att_20min\", 0)\n",
    "            for doc in recent_docs\n",
    "            if isinstance(doc.metadata.get(\"att_20min\"), (float, int))\n",
    "        ]\n",
    "        if len(att_20s) >= 3 and sum(att_20s) / len(att_20s) < 0.6:\n",
    "            print(\"ğŸ˜´ 20dk ortalaman dÃ¼ÅŸÃ¼k. Mola vermelisin.\")\n",
    "            try:\n",
    "                import winsound\n",
    "                winsound.Beep(800, 500)\n",
    "            except:\n",
    "                pass\n",
    "            print(\"\\033[95m[Mola Ã–nerisi: DÃ¼ÅŸÃ¼k dikkat algÄ±landÄ±.]\\033[0m\")\n",
    "    except Exception as e:\n",
    "        print(f\"ğŸš¨ Mola modÃ¼lÃ¼ hatasÄ±: {e}\")\n",
    "\n",
    "def periyot_onerisi_llm_ileri(_):\n",
    "    try:\n",
    "        recent_docs = vectordb.similarity_search(\"attention\", k=15)\n",
    "        att_vals = [doc.metadata.get(\"attention\", 0) for doc in recent_docs]\n",
    "        focus_vals = [doc.metadata.get(\"focus_score\", 0) for doc in recent_docs]\n",
    "        attention_summary = \"\\n\".join([\n",
    "            f\"- Dikkat: {round(doc.metadata.get('attention', 0),2)} \"\n",
    "            f\"| 20dk: {round(doc.metadata.get('att_20min', 0),2)} \"\n",
    "            f\"| Focus: {round(doc.metadata.get('focus_score', 0),2)}\"\n",
    "            for doc in recent_docs\n",
    "        ])\n",
    "        if len(att_vals) < 5:\n",
    "            print(\"ğŸ” KiÅŸisel Ã¶neri iÃ§in yeterli veri yok.\")\n",
    "            return\n",
    "\n",
    "        prompt = f\"\"\"\n",
    "ğŸ§  Ã–ÄŸrenci dikkat geÃ§miÅŸi:\n",
    "{attention_summary}\n",
    "\n",
    "ğŸ“Š Ortalama dikkat: {round(sum(att_vals)/len(att_vals), 2)}\n",
    "ğŸ™ï¸ Ortalama focus: {round(sum(focus_vals)/len(focus_vals), 2)}\n",
    "\n",
    "Bu Ã¶ÄŸrenciye uygun Ã¶ÄŸrenme periyodu ve stratejileri Ã¶ner.\n",
    "\"\"\"\n",
    "        feedback = qa_chain.run(prompt)\n",
    "        print(\"\\nğŸ§  Ã–ÄŸrenme Ã–nerisi:\\n\", feedback)\n",
    "    except Exception as e:\n",
    "        print(f\"ğŸš¨ Ã–ÄŸrenme Ã¶nerisi hatasÄ±: {e}\")\n",
    "\n",
    "def zihin_yorgunlugu_tahmini(_):\n",
    "    try:\n",
    "        recent_docs = vectordb.similarity_search(\"attention\", k=10)\n",
    "        if len(recent_docs) < 5:\n",
    "            print(\"ğŸ” Yorgunluk analizi iÃ§in yeterli veri yok.\")\n",
    "            return\n",
    "\n",
    "        attention_values = [doc.metadata.get(\"attention\", 0) for doc in recent_docs]\n",
    "        first_half_avg = sum(attention_values[:3]) / 3\n",
    "        last_half_avg = sum(attention_values[-3:]) / 3\n",
    "        delta = first_half_avg - last_half_avg\n",
    "\n",
    "        if delta > 0.15:\n",
    "            print(\"ğŸ§  Zihin yorgunluÄŸu tespit edildi. Dikkatin ciddi oranda dÃ¼ÅŸtÃ¼.\")\n",
    "            try:\n",
    "                import winsound\n",
    "                winsound.Beep(600, 500)\n",
    "            except:\n",
    "                pass\n",
    "            print(\"\\033[93m[Yorgunluk AlgÄ±landÄ±: KÄ±sa bir ara vermelisin.]\\033[0m\")\n",
    "    except Exception as e:\n",
    "        print(f\"ğŸš¨ Yorgunluk tahmin modÃ¼lÃ¼ hatasÄ±: {e}\")\n",
    "\n",
    "def vak_ogrenme_tarzi_tahmini(_):\n",
    "    try:\n",
    "        recent_docs = vectordb.similarity_search(\"attention\", k=10)\n",
    "        visual = auditory = kinesthetic = 0\n",
    "\n",
    "        for doc in recent_docs:\n",
    "            m = doc.metadata\n",
    "            if m.get(\"screen\"): visual += 1\n",
    "            if m.get(\"focus_score\", 0) > 0.6: auditory += 1\n",
    "            if m.get(\"keyboard_activity\") or m.get(\"mouse_activity\"): kinesthetic += 1\n",
    "\n",
    "        toplam = visual + auditory + kinesthetic\n",
    "        if toplam == 0:\n",
    "            print(\"ğŸ” Ã–ÄŸrenme tarzÄ± iÃ§in yeterli veri yok.\")\n",
    "            return\n",
    "\n",
    "        style = max(\n",
    "            (visual, \"GÃ¶rsel\"),\n",
    "            (auditory, \"Ä°ÅŸitsel\"),\n",
    "            (kinesthetic, \"Kinestetik\"),\n",
    "        )[1]\n",
    "        print(f\"ğŸ“š Tahmini Ã¶ÄŸrenme tarzÄ±n: \\033[94m{style}\\033[0m\")\n",
    "    except Exception as e:\n",
    "        print(f\"ğŸš¨ Ã–ÄŸrenme tarzÄ± modÃ¼lÃ¼ hatasÄ±: {e}\")\n",
    "\n",
    "def oturum_ozet_raporu(_):\n",
    "    try:\n",
    "        recent_docs = vectordb.similarity_search(\"attention\", k=10)\n",
    "        if not recent_docs:\n",
    "            print(\"ğŸ” Ã–zet iÃ§in yeterli veri yok.\")\n",
    "            return\n",
    "\n",
    "        avg_att = sum(doc.metadata.get(\"attention\", 0) for doc in recent_docs) / len(recent_docs)\n",
    "        avg_focus = sum(doc.metadata.get(\"focus_score\", 0) for doc in recent_docs) / len(recent_docs)\n",
    "        en_focused = max(recent_docs, key=lambda d: d.metadata.get(\"focus_score\", 0))\n",
    "        saat = en_focused.metadata.get(\"timestamp\", \"bilinmiyor\")\n",
    "\n",
    "        print(\"\\nğŸ“Š \\033[92mOturum Ã–zeti:\\033[0m\")\n",
    "        print(f\"- Ortalama dikkat: {round(avg_att, 2)}\")\n",
    "        print(f\"- Ortalama focus: {round(avg_focus, 2)}\")\n",
    "        print(f\"- En odaklÄ± zaman: {saat}\")\n",
    "    except Exception as e:\n",
    "        print(f\"ğŸš¨ Oturum Ã¶zeti hatasÄ±: {e}\")\n",
    "\n",
    "def sesli_motivasyon_ver(mesaj=\"Harika gidiyorsun! Odaklanmaya devam et.\"):\n",
    "    try:\n",
    "        engine = pyttsx3.init()\n",
    "        engine.setProperty('rate', 175)\n",
    "        engine.say(mesaj)\n",
    "        engine.runAndWait()\n",
    "    except Exception as e:\n",
    "        print(f\"[Sesli UyarÄ± HatasÄ±] {e}\")\n",
    "\n",
    "def analiz_sorudan_anlam_cikar_ve_yanitla(soru: str):\n",
    "    try:\n",
    "        recent_docs = vectordb.similarity_search(\"attention\", k=10)\n",
    "        attention_lines = \"\\n\".join([\n",
    "            f\"- Dikkat: {round(doc.metadata.get('attention', 0), 2)} \"\n",
    "            f\"| Focus: {round(doc.metadata.get('focus_score', 0), 2)}\"\n",
    "            for doc in recent_docs\n",
    "        ])\n",
    "        prompt = f\"\"\"\n",
    "KullanÄ±cÄ±nÄ±n sorusu: \"{soru}\"\n",
    "\n",
    "AÅŸaÄŸÄ±da kullanÄ±cÄ±nÄ±n son dikkat ve etkileÅŸim verileri var:\n",
    "{attention_lines}\n",
    "\n",
    "Bu verilerle birlikte, kullanÄ±cÄ±nÄ±n sorusuna cevap ver:\n",
    "- Soruyu anlamlandÄ±r.\n",
    "- EÄŸer performans sorusuysa analiz yap.\n",
    "- Yorgunluksa belirt.\n",
    "- Motivasyon istiyorsa cesaretlendir.\n",
    "- Ã–ÄŸrenme Ã¶nerisi istiyorsa tavsiye ver.\n",
    "- KonuÅŸma tonun sÄ±cak ve koÃ§vari olsun.\n",
    "\"\"\"\n",
    "        yanit = LLM.invoke(prompt)\n",
    "        return yanit\n",
    "    except Exception as e:\n",
    "        return f\"[Analiz HatasÄ±] {e}\"\n",
    "    \n",
    "    \n",
    "def ozet_ses_logs(_):\n",
    "    # 1. ham kayÄ±tlarÄ± oku\n",
    "    log_path = \"system_session_full.txt\"\n",
    "    try:\n",
    "        with open(log_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            text = f.read()\n",
    "    except Exception as e:\n",
    "        return f\"âŒ Log dosyasÄ± okunamadÄ±: {e}\"\n",
    "\n",
    "    # 2. LLM ile uzun metni bÃ¶lÃ¼p Ã¶zet Ã§Ä±kar\n",
    "    #    Burada qa_chain veya LLM.invoke kullanabilirsiniz\n",
    "    chunks = [ text[i:i+2000] for i in range(0, len(text), 2000) ]\n",
    "    summaries = []\n",
    "    for chunk in chunks:\n",
    "        prompt = f\"\"\"AÅŸaÄŸÄ±daki zaman damgalÄ± ses kaydÄ±nÄ± Ã¶zetle ve Ã¶nemli noktalarÄ± maddele:\\n\\n{chunk}\"\"\"\n",
    "        summaries.append( qa_chain.run(prompt) )\n",
    "    full_summary = \"\\n\\n\".join(summaries)\n",
    "\n",
    "    # 3. PDF oluÅŸtur\n",
    "    pdf_path = \"session_summary.pdf\"\n",
    "    try:\n",
    "        c = canvas.Canvas(pdf_path, pagesize=A4)\n",
    "        width, height = A4\n",
    "        text_obj = c.beginText(40, height - 40)\n",
    "        text_obj.setFont(\"Helvetica\", 11)\n",
    "        for line in full_summary.split(\"\\n\"):\n",
    "            text_obj.textLine(line)\n",
    "            # sayfa dolarsa yeni sayfa aÃ§\n",
    "            if text_obj.getY() < 40:\n",
    "                c.drawText(text_obj)\n",
    "                c.showPage()\n",
    "                text_obj = c.beginText(40, height - 40)\n",
    "                text_obj.setFont(\"Helvetica\", 11)\n",
    "        c.drawText(text_obj)\n",
    "        c.save()\n",
    "    except Exception as e:\n",
    "        return f\"âŒ PDF oluÅŸturulurken hata: {e}\"\n",
    "\n",
    "    return f\"âœ… Ã–zet PDF hazÄ±r: {pdf_path}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4a90c8e",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b97f13e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_29520\\3422287574.py:20: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
      "  agent = initialize_agent(\n"
     ]
    }
   ],
   "source": [
    "# AraÃ§larÄ± tanÄ±mla\n",
    "tools = [\n",
    "    Tool(name=\"DikkatUyarisi\", func=dikkat_uyarisi_ver, description=\"Dikkat seviyesi dÃ¼ÅŸÃ¼kse uyarÄ± verir.\"),\n",
    "    Tool(name=\"MolaOnerisi\", func=mola_onerisi_chromadb, description=\"20dk ortalama dikkat dÃ¼ÅŸÃ¼klÃ¼ÄŸÃ¼nde mola Ã¶nerir.\"),\n",
    "    Tool(name=\"OgrenmePeriyoduOnerisi\", func=periyot_onerisi_llm_ileri, description=\"Dikkat geÃ§miÅŸine gÃ¶re Ã¶ÄŸrenme stratejisi Ã¶nerir.\"),\n",
    "    Tool(name=\"ZihinYorgunluguTahmini\", func=zihin_yorgunlugu_tahmini, description=\"Son dikkat verilerindeki dÃ¼ÅŸÃ¼ÅŸe gÃ¶re zihin yorgunluÄŸu tespit eder.\"),\n",
    "    Tool(name=\"OgrenmeTarziTahmini\", func=vak_ogrenme_tarzi_tahmini, description=\"KullanÄ±cÄ±nÄ±n VAK Ã¶ÄŸrenme tarzÄ±nÄ± tahmin eder.\"),\n",
    "    Tool(name=\"OturumOzeti\", func=oturum_ozet_raporu, description=\"Son verilerle oturum Ã¶zeti sunar.\"),\n",
    "    Tool(name=\"SoruyaGoreAnalizYap\", func=analiz_sorudan_anlam_cikar_ve_yanitla, description=\"Soruya gÃ¶re analiz yapar ve LLM ile cevap Ã¼retir.\"),\n",
    "    Tool(name=\"SesOzetPDF\", func=ozet_ses_logs, description=\"`system_session_full.txt` dosyasÄ±ndaki tÃ¼m ses kayÄ±tlarÄ±nÄ± LLM ile Ã¶zetler ve PDF olarak kaydeder.\")\n",
    "]\n",
    "\n",
    "# Agent'Ä± baÅŸlat\n",
    "system_prompt = \"\"\"\n",
    "Sen bir eÄŸitim koÃ§usun.\n",
    "- SayÄ±sal metrik kullanma, sadece nitel ifadeler (Ã§ok yÃ¼ksek/orta/dÃ¼ÅŸÃ¼k) kullan.\n",
    "- KonuÅŸman sÄ±cakkanlÄ±, destekleyici ve motive edici olsun.\n",
    "- Gerekirse araÃ§larÄ± (Tools) Ã§aÄŸÄ±r.\n",
    "\"\"\"\n",
    "agent = initialize_agent(\n",
    "    tools=tools,\n",
    "    llm=LLM,\n",
    "    agent_type=AgentType.ZERO_SHOT_REACT_DESCRIPTION,\n",
    "    verbose=True,\n",
    "    system_message=system_prompt\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f27ad3",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8dfdbe94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "# 2) YardÄ±mcÄ± Fonksiyonlar\n",
    "# â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”â€”\n",
    "def get_safe_json(url):\n",
    "    try:\n",
    "        resp = requests.get(url, timeout=5)\n",
    "        if resp.status_code == 200 and resp.text.strip():\n",
    "            return resp.json()\n",
    "    except:\n",
    "        pass\n",
    "    return {}\n",
    "\n",
    "def kvalitatif_deger(score):\n",
    "    if score is None: return \"Ã¶lÃ§Ã¼lemediÄŸi\"\n",
    "    if score >= 0.8:     return \"Ã§ok yÃ¼ksek\"\n",
    "    if score >= 0.5:     return \"orta\"\n",
    "    return \"dÃ¼ÅŸÃ¼k\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df2e3a70",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70f082de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Flask API sunucusu baÅŸlatÄ±ldÄ±: http://localhost:8005\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\n",
      " * Running on all addresses (0.0.0.0)\n",
      " * Running on http://127.0.0.1:8005\n",
      " * Running on http://192.168.1.126:8005\n",
      "Press CTRL+C to quit\n",
      "127.0.0.1 - - [06/Aug/2025 15:31:34] \"OPTIONS /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:31:34] \"GET /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:31:35] \"GET /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:31:36] \"GET /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:31:37] \"GET /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:31:37] \"OPTIONS /ask HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:31:38] \"GET /last_response HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeÃ§miÅŸ sohbet alma hatasÄ±: Expected where to have exactly one operator, got {'user_id': 'ogrenci_001', 'type': 'conversation'} in query.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hp\\AppData\\Local\\Temp\\ipykernel_29520\\1879942637.py:75: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  yanit = agent.run(prompt)\n",
      "Retrying langchain_google_genai.llms._completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash-exp\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 50\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 20\n",
      "}\n",
      "].\n",
      "127.0.0.1 - - [06/Aug/2025 15:31:39] \"GET /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:31:40] \"OPTIONS /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:31:40] \"GET /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:31:41] \"GET /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:31:42] \"GET /last_response HTTP/1.1\" 200 -\n",
      "Retrying langchain_google_genai.llms._completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash-exp\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 50\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 15\n",
      "}\n",
      "].\n",
      "127.0.0.1 - - [06/Aug/2025 15:31:43] \"GET /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:31:44] \"GET /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:31:45] \"GET /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:31:46] \"OPTIONS /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:31:46] \"GET /last_response HTTP/1.1\" 200 -\n",
      "Retrying langchain_google_genai.llms._completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash-exp\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 50\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 11\n",
      "}\n",
      "].\n",
      "127.0.0.1 - - [06/Aug/2025 15:31:47] \"GET /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:31:48] \"GET /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:31:49] \"GET /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:31:50] \"GET /last_response HTTP/1.1\" 200 -\n",
      "Retrying langchain_google_genai.llms._completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash-exp\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 50\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 7\n",
      "}\n",
      "].\n",
      "127.0.0.1 - - [06/Aug/2025 15:31:51] \"GET /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:31:52] \"OPTIONS /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:31:52] \"GET /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:31:53] \"GET /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:31:54] \"GET /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:31:55] \"GET /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:31:56] \"GET /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:31:57] \"GET /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:31:58] \"OPTIONS /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:31:58] \"GET /last_response HTTP/1.1\" 200 -\n",
      "Retrying langchain_google_genai.llms._completion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash-exp\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 50\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 59\n",
      "}\n",
      "].\n",
      "127.0.0.1 - - [06/Aug/2025 15:31:59] \"GET /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:32:00] \"GET /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:32:01] \"GET /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:32:02] \"GET /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:32:03] \"GET /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:32:04] \"OPTIONS /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:32:04] \"GET /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:32:05] \"GET /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:32:06] \"GET /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:32:07] \"GET /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:32:08] \"GET /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:32:09] \"GET /last_response HTTP/1.1\" 200 -\n",
      "Retrying langchain_google_genai.llms._completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash-exp\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 50\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 49\n",
      "}\n",
      "].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent Ã§alÄ±ÅŸtÄ±rma hatasÄ±: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash-exp\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 50\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 49\n",
      "}\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [06/Aug/2025 15:32:10] \"OPTIONS /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:32:10] \"GET /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:32:11] \"GET /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:32:12] \"GET /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:32:13] \"GET /last_response HTTP/1.1\" 200 -\n",
      "Retrying langchain_google_genai.llms._completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash-exp\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 50\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 45\n",
      "}\n",
      "].\n",
      "127.0.0.1 - - [06/Aug/2025 15:32:14] \"GET /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:32:15] \"GET /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:32:16] \"OPTIONS /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:32:16] \"GET /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:32:17] \"GET /last_response HTTP/1.1\" 200 -\n",
      "Retrying langchain_google_genai.llms._completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash-exp\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 50\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 41\n",
      "}\n",
      "].\n",
      "127.0.0.1 - - [06/Aug/2025 15:32:18] \"GET /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:32:19] \"GET /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:32:20] \"GET /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:32:21] \"GET /last_response HTTP/1.1\" 200 -\n",
      "Retrying langchain_google_genai.llms._completion_with_retry.<locals>._completion_with_retry in 8.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash-exp\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 50\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 37\n",
      "}\n",
      "].\n",
      "127.0.0.1 - - [06/Aug/2025 15:32:22] \"OPTIONS /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:32:22] \"GET /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:32:23] \"GET /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:32:24] \"GET /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:32:25] \"GET /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:32:26] \"GET /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:32:27] \"GET /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:32:28] \"OPTIONS /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:32:28] \"GET /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:32:29] \"GET /last_response HTTP/1.1\" 200 -\n",
      "Retrying langchain_google_genai.llms._completion_with_retry.<locals>._completion_with_retry in 10.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash-exp\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 50\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 28\n",
      "}\n",
      "].\n",
      "127.0.0.1 - - [06/Aug/2025 15:32:30] \"GET /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:32:31] \"GET /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:32:32] \"GET /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:32:33] \"GET /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:32:34] \"OPTIONS /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:32:34] \"GET /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:32:35] \"GET /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:32:36] \"GET /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:32:37] \"GET /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:32:38] \"GET /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:32:39] \"GET /last_response HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM hatasÄ±: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash-exp\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 50\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 18\n",
      "}\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127.0.0.1 - - [06/Aug/2025 15:32:40] \"OPTIONS /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:32:40] \"POST /ask HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:32:40] \"GET /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:32:41] \"GET /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:32:41] \"GET /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:32:42] \"GET /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:32:43] \"GET /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:32:44] \"GET /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:32:45] \"GET /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:32:46] \"OPTIONS /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:32:46] \"GET /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:32:47] \"GET /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:32:48] \"GET /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:32:49] \"GET /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:32:50] \"GET /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:32:51] \"GET /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:32:52] \"OPTIONS /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:32:52] \"GET /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:32:53] \"GET /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:32:54] \"GET /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:32:55] \"GET /last_response HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [06/Aug/2025 15:32:56] \"GET /last_response HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "# Flask API uygulamasÄ±\n",
    "app = Flask(__name__)\n",
    "CORS(app)\n",
    "\n",
    "last_agent_response = \"HenÃ¼z agent Ã§alÄ±ÅŸmadÄ±.\"\n",
    "last_alert = None\n",
    "\n",
    "@app.route(\"/download_session_summary\", methods=[\"GET\"])\n",
    "def download_session_summary():\n",
    "    pdf_path = \"session_summary.pdf\"\n",
    "    if not os.path.exists(pdf_path):\n",
    "        return jsonify({\n",
    "            \"error\": \"Ã–zet PDF henÃ¼z oluÅŸturulmadÄ±. Agent'a SesOzetPDF aracÄ±nÄ± Ã§alÄ±ÅŸtÄ±r deyin.\"\n",
    "        }), 404\n",
    "    return send_file(pdf_path, as_attachment=True)\n",
    "\n",
    "@app.route(\"/last_response\", methods=[\"GET\"])\n",
    "def get_last_response():\n",
    "    response = {\n",
    "        \"answer\": last_agent_response\n",
    "    }\n",
    "    if last_alert is not None:\n",
    "        response[\"alert\"] = last_alert\n",
    "    return jsonify(response)\n",
    "\n",
    "@app.route(\"/ask\", methods=[\"POST\"])\n",
    "def ask_agent():\n",
    "    global last_agent_response, last_alert\n",
    "\n",
    "    try:\n",
    "        data = request.get_json() or {}\n",
    "        soru = data.get(\"question\", \"\").strip()\n",
    "        if not soru:\n",
    "            return jsonify({\"error\": \"Soru boÅŸ olamaz.\"}), 400\n",
    "\n",
    "        session_id = datetime.now().strftime(\"%Y%m%d_%H\")\n",
    "        now_ts = datetime.now().isoformat()\n",
    "\n",
    "        # â€” KullanÄ±cÄ± mesajÄ±nÄ± kaydet\n",
    "        try:\n",
    "            vectordb.add_texts(\n",
    "                [soru],\n",
    "                metadatas=[{\n",
    "                    \"user_id\": STUDENT_ID,\n",
    "                    \"session_id\": session_id,\n",
    "                    \"timestamp\": now_ts,\n",
    "                    \"type\": \"conversation\",\n",
    "                    \"speaker\": \"User\"\n",
    "                }]\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"VeritabanÄ± kayÄ±t hatasÄ±: {e}\")\n",
    "\n",
    "        # â€” Ã–nceki 5 sohbeti getir\n",
    "        try:\n",
    "            conv_docs = vectordb.similarity_search(\n",
    "                soru, k=5,\n",
    "                filter={\"user_id\": STUDENT_ID, \"type\": \"conversation\"}\n",
    "            )\n",
    "            history = \"\\n\".join(f\"{d.metadata['speaker']}: {d.page_content}\" for d in conv_docs)\n",
    "        except Exception as e:\n",
    "            print(f\"GeÃ§miÅŸ sohbet alma hatasÄ±: {e}\")\n",
    "            history = \"\"\n",
    "\n",
    "        # â€” Context + soru ile prompt oluÅŸtur\n",
    "        prompt = f\"\"\"\n",
    "Ã–nceki konuÅŸmalar:\n",
    "{history}\n",
    "\n",
    "KullanÄ±cÄ±: {soru}\n",
    "\"\"\"\n",
    "\n",
    "        # Agent'Ä± gÃ¼venli ÅŸekilde Ã§alÄ±ÅŸtÄ±r\n",
    "        try:\n",
    "            yanit = agent.run(prompt)\n",
    "        except Exception as agent_error:\n",
    "            print(f\"Agent Ã§alÄ±ÅŸtÄ±rma hatasÄ±: {agent_error}\")\n",
    "            # Basit bir yanÄ±t Ã¼ret\n",
    "            try:\n",
    "                yanit = LLM.invoke(f\"EÄŸitim koÃ§u olarak ÅŸu soruya cevap ver: {soru}\")\n",
    "            except Exception as llm_error:\n",
    "                print(f\"LLM hatasÄ±: {llm_error}\")\n",
    "                yanit = \"ÃœzgÃ¼nÃ¼m, ÅŸu anda teknik bir sorun yaÅŸÄ±yorum. LÃ¼tfen daha sonra tekrar deneyin.\"\n",
    "\n",
    "        # â€” Agent cevabÄ±nÄ± kaydet\n",
    "        try:\n",
    "            vectordb.add_texts(\n",
    "                [yanit],\n",
    "                metadatas=[{\n",
    "                    \"user_id\": STUDENT_ID,\n",
    "                    \"session_id\": session_id,\n",
    "                    \"timestamp\": datetime.now().isoformat(),\n",
    "                    \"type\": \"conversation\",\n",
    "                    \"speaker\": \"Agent\"\n",
    "                }]\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"Cevap kayÄ±t hatasÄ±: {e}\")\n",
    "\n",
    "        # Buraya istersen ask_agent iÃ§inde de last_alert reset veya gÃ¼ncelleme ekleyebilirsin\n",
    "        last_agent_response = yanit\n",
    "\n",
    "        return jsonify({\"answer\": yanit})\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Genel API hatasÄ±: {e}\")\n",
    "        error_response = \"Teknik bir sorun oluÅŸtu. LÃ¼tfen daha sonra tekrar deneyin.\"\n",
    "        return jsonify({\"answer\": error_response, \"error\": str(e)}), 500\n",
    "\n",
    "# Flask sunucusunu ayrÄ± bir thread'de baÅŸlat\n",
    "def start_flask_server():\n",
    "    try:\n",
    "        app.run(host=\"0.0.0.0\", port=8005, debug=False, threaded=True)\n",
    "    except Exception as e:\n",
    "        print(f\"Flask sunucu baÅŸlatma hatasÄ±: {e}\")\n",
    "\n",
    "flask_thread = threading.Thread(target=start_flask_server, daemon=True)\n",
    "flask_thread.start()\n",
    "\n",
    "print(\"ğŸš€ Flask API sunucusu baÅŸlatÄ±ldÄ±: http://localhost:8005\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c12d04",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4955814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ AI Agent ana dÃ¶ngÃ¼sÃ¼ baÅŸlatÄ±lÄ±yor...\n",
      "\n",
      "ğŸ“Š \u001b[92mOturum Ã–zeti:\u001b[0m\n",
      "- Ortalama dikkat: 0.66\n",
      "- Ortalama focus: 0.0\n",
      "- En odaklÄ± zaman: 2025-08-06T13:21:09.584329\n",
      "\n",
      "ğŸ§  Karar verildi: Rastgele Ã¶zete yÃ¶nlendirildi.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Retrying langchain_google_genai.llms._completion_with_retry.<locals>._completion_with_retry in 4.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
      "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
      "  quota_id: \"GenerateRequestsPerDayPerProjectPerModel-FreeTier\"\n",
      "  quota_dimensions {\n",
      "    key: \"model\"\n",
      "    value: \"gemini-2.0-flash-exp\"\n",
      "  }\n",
      "  quota_dimensions {\n",
      "    key: \"location\"\n",
      "    value: \"global\"\n",
      "  }\n",
      "  quota_value: 50\n",
      "}\n",
      ", links {\n",
      "  description: \"Learn more about Gemini API quotas\"\n",
      "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
      "}\n",
      ", retry_delay {\n",
      "  seconds: 4\n",
      "}\n",
      "].\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sohbet GeÃ§miÅŸi HatasÄ±] Expected where to have exactly one operator, got {'user_id': 'ogrenci_001', 'type': 'conversation'} in query.\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# Ana dÃ¶ngÃ¼\n",
    "print(\"ğŸš€ AI Agent ana dÃ¶ngÃ¼sÃ¼ baÅŸlatÄ±lÄ±yor...\")\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        # Veri kaynaklarÄ±ndan Ã§ek\n",
    "        data = get_safe_json(ENDPOINT_ATTENTION)\n",
    "        keyboard_data = get_safe_json(ENDPOINT_KYBRD_MOUSE_INTERRUPT)\n",
    "        script_data = get_safe_json(ENDPOINT_SCRIPT)\n",
    "\n",
    "        if not data:\n",
    "            print(\"â³ Veri alÄ±namadÄ±, bekleniyor...\\n\")\n",
    "            time.sleep(2)\n",
    "            continue\n",
    "\n",
    "        # Oturum bilgileri\n",
    "        CURRENT_USER_ID = \"ogrenci_001\"\n",
    "        CURRENT_SESSION_ID = datetime.now().strftime(\"%Y%m%d_%H\")\n",
    "        CURRENT_TIMESTAMP = datetime.now().isoformat()\n",
    "\n",
    "        # â€”â€”â€” Metadata oluÅŸtur â€”â€”â€”\n",
    "        metadata = {\n",
    "            \"user_id\": CURRENT_USER_ID,\n",
    "            \"session_id\": CURRENT_SESSION_ID,\n",
    "            \"timestamp\": CURRENT_TIMESTAMP,\n",
    "            \"attention\": data.get(\"attention\", 0),\n",
    "            \"screen\": data.get(\"head_looking_at_screen\", False),\n",
    "            \"eye_left\": data.get(\"left_eye_open\", False),\n",
    "            \"eye_right\": data.get(\"right_eye_open\", False),\n",
    "            \"att_1min\": data.get(\"attention_1min_avg\", 0),\n",
    "            \"att_5min\": data.get(\"attention_5min_avg\", 0),\n",
    "            \"att_20min\": data.get(\"attention_20min_avg\", 0),\n",
    "            \"att_total\": data.get(\"attention_total_avg\", 0),\n",
    "            \"keyboard_activity\": keyboard_data.get(\"keyboard_activity\", False),\n",
    "            \"mouse_activity\": keyboard_data.get(\"mouse_activity\", False),\n",
    "            \"tab_changed\": keyboard_data.get(\"tab_changed\", False),\n",
    "            \"interaction_status\": keyboard_data.get(\"status\", \"no_status\"),\n",
    "            # focus_score artÄ±k None da olabilir\n",
    "            \"focus_score\": script_data.get(\"focus_score\")\n",
    "        }\n",
    "\n",
    "        # Veriyi gÃ¼venli ÅŸekilde kaydet\n",
    "        try:\n",
    "            vectordb.add_texts(\n",
    "                [\"<sensor data>\"],\n",
    "                metadatas=[{**metadata, \"type\":\"sensor\"}]\n",
    "            )\n",
    "        except Exception as e:\n",
    "            print(f\"[Veri KayÄ±t HatasÄ±] {e}\")\n",
    "\n",
    "        # ChromaDB temizliÄŸi (300 kayÄ±t sÄ±nÄ±rÄ±)\n",
    "        try:\n",
    "            collection_data = vectordb._collection.get()\n",
    "            if len(collection_data.get(\"ids\", [])) > 300:\n",
    "                vectordb._collection.delete(ids=collection_data[\"ids\"][:50])\n",
    "                print(\"â™»ï¸ ChromaDB Ã§ok dolu, eski kayÄ±tlar silindi.\")\n",
    "        except Exception as e:\n",
    "            print(f\"[ChromaDB Temizleme HatasÄ±] {e}\")\n",
    "\n",
    "        # Karar mekanizmasÄ±\n",
    "        try:\n",
    "            recent_docs = vectordb.similarity_search(\"attention\", k=10)\n",
    "\n",
    "            # Ortalama dikkat\n",
    "            recent_attention = [d.metadata.get(\"attention\", 0) for d in recent_docs]\n",
    "            avg_attention = sum(recent_attention) / len(recent_attention) if recent_attention else 0\n",
    "\n",
    "            # Ortalama focus (None deÄŸerleri atla)\n",
    "            focus_vals = [\n",
    "                d.metadata.get(\"focus_score\")\n",
    "                for d in recent_docs\n",
    "                if isinstance(d.metadata.get(\"focus_score\"), (int, float))\n",
    "            ]\n",
    "            avg_focus = sum(focus_vals) / len(focus_vals) if focus_vals else 0\n",
    "\n",
    "            decision = None\n",
    "\n",
    "            if metadata[\"attention\"] < 0.3 and not metadata[\"screen\"]:\n",
    "                dikkat_uyarisi_ver(None)\n",
    "                decision = \"Dikkat Ã§ok dÃ¼ÅŸÃ¼k ve ekran dÄ±ÅŸÄ±.\"\n",
    "\n",
    "            elif metadata[\"att_20min\"] < 0.5 and avg_attention < 0.45:\n",
    "                mola_onerisi_chromadb(None)\n",
    "                decision = \"20dk ortalama dikkat Ã§ok dÃ¼ÅŸÃ¼k.\"\n",
    "\n",
    "            elif avg_attention > 0.6 and metadata[\"attention\"] < 0.4:\n",
    "                zihin_yorgunlugu_tahmini(None)\n",
    "                decision = \"Zihin yorgunluÄŸu olabilir.\"\n",
    "\n",
    "            # focus_score None deÄŸilse ve yÃ¼ksekse motivasyon ver\n",
    "            elif metadata[\"focus_score\"] is not None and metadata[\"focus_score\"] > 0.85:\n",
    "                sesli_motivasyon_ver(\"Odak harika! BÃ¶yle devam et.\")\n",
    "                decision = \"Odak Ã§ok iyi, motivasyon verildi.\"\n",
    "\n",
    "            # sadece gerÃ§ek bir focus_score varsa etkileÅŸim uyarÄ±sÄ±\n",
    "            elif (not metadata[\"keyboard_activity\"]\n",
    "                  and not metadata[\"mouse_activity\"]\n",
    "                  and metadata[\"focus_score\"] is not None):\n",
    "                vak_ogrenme_tarzi_tahmini(None)\n",
    "                sesli_motivasyon_ver(\"Biraz etkileÅŸim gerekebilir. Hadi devam!\")\n",
    "                decision = \"EtkileÅŸim yoktu, Ã¶ÄŸrenme tarzÄ± tahmini yapÄ±ldÄ±.\"\n",
    "\n",
    "            elif random.random() < 0.1:\n",
    "                oturum_ozet_raporu(None)\n",
    "                decision = \"Rastgele Ã¶zete yÃ¶nlendirildi.\"\n",
    "\n",
    "            if decision:\n",
    "                print(f\"\\nğŸ§  Karar verildi: {decision}\")\n",
    "\n",
    "                # â€” Nitel tanÄ±mlamalar\n",
    "                att_desc    = kvalitatif_deger(metadata[\"attention\"])\n",
    "                focus_desc  = kvalitatif_deger(metadata[\"focus_score\"])\n",
    "                interaction = \"var\" if (metadata[\"keyboard_activity\"] or metadata[\"mouse_activity\"]) else \"yok\"\n",
    "\n",
    "                # â€” Ã–nceki sohbetleri al\n",
    "                try:\n",
    "                    conv_docs = vectordb.similarity_search(\n",
    "                        decision, k=5,\n",
    "                        filter={\"user_id\": STUDENT_ID, \"type\": \"conversation\"}\n",
    "                    )\n",
    "                    history = \"\\n\".join(f\"{d.metadata['speaker']}: {d.page_content}\" for d in conv_docs)\n",
    "                except Exception as e:\n",
    "                    print(f\"[Sohbet GeÃ§miÅŸi HatasÄ±] {e}\")\n",
    "                    history = \"\"\n",
    "\n",
    "                # â€” Nitel ifadeli prompt\n",
    "                prompt = f\"\"\"\n",
    "        Ã–nceki konuÅŸmalar:\n",
    "        {history}\n",
    "\n",
    "        Durum: {decision}\n",
    "        - Odak durumu: {att_desc}\n",
    "        - Derin odak: {focus_desc}\n",
    "        - EtkileÅŸim: {interaction}\n",
    "\n",
    "        LÃ¼tfen sayÄ±sal deÄŸer vermeden, sÄ±cak ve destekleyici bir mesaj yaz.\n",
    "        \"\"\"\n",
    "                try:\n",
    "                    fb = agent.run(prompt)\n",
    "                    last_agent_response = fb\n",
    "                except Exception as e:\n",
    "                    print(f\"[Agent HatasÄ±] {e}\")\n",
    "                    # Basit bir geri bildirim ver\n",
    "                    last_agent_response = f\"Durumun takip edildi: {decision}\"\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"ğŸ§  [Zeki KoÃ§ HatasÄ±] {e}\")\n",
    "\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nğŸ›‘ Program durduruldu (Ctrl+C)\")\n",
    "        break\n",
    "    except Exception as e:\n",
    "        print(f\"ğŸš¨ [Ana DÃ¶ngÃ¼ HatasÄ±] {e}\")\n",
    "        print(\"ğŸ”„ 5 saniye bekleyip devam ediyorum...\")\n",
    "        time.sleep(5)\n",
    "        continue\n",
    "\n",
    "    # DÃ¶ngÃ¼ arasÄ± bekleme\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82265f79",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI_Agent",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
